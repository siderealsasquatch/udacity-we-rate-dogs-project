{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the necessary libararies\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "# Allow inline plotting, have plots use seaborn styling, turn off seaborn warnings\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by retrieving image-predictions.tsv file\n",
    "image_pred_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "with open('image-predictions.tsv', 'wb') as image_pred_file:\n",
    "    image_pred_gathered = requests.get(image_pred_url)\n",
    "    image_pred_file.write(image_pred_gathered.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for retrieving tweet data for each of the tweet ids contained in the WeRateDogs twitter\n",
    "# archive. This code can be run but since the file containing the api keys isn't included in\n",
    "# the project submission for security reasons, the code is presented here for review purposes\n",
    "# only. A reviewer is free to try this code using his/her own api keys. From this point on,\n",
    "# assume that this code has been run and the file containing the gathered data is present in the\n",
    "# current working directory\n",
    "import credentials as cred\n",
    "\n",
    "# Create tweepy api object\n",
    "auth = tweepy.OAuthHandler(cred.consumer_key, cred.consumer_secret)\n",
    "auth.set_access_token(cred.access_token, cred.access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# Get all of the tweet data for each tweet id\n",
    "tweet_ids = pd.read_csv('twitter-archive-enhanced.csv').tweet_id.astype(str).tolist()\n",
    "with open('tweet_json.txt', 'w') as tweet_data_file:\n",
    "    for tweet_id in tweet_ids:\n",
    "        try:\n",
    "            tweet_data = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        except tweepy.TweepError:\n",
    "            pass\n",
    "        else:\n",
    "            tweet_data_file.write(json.dumps(tweet_data._json) + '\\n')\n",
    "            print('Retrieved data for tweet id: {}'.format(tweet_id))\n",
    "print('Retrieved data for all tweet ids.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the tweet data that we just retrieved.\n",
    "tweet_data = []\n",
    "with open('tweet_json.txt') as data_file:\n",
    "    for json_obj in data_file:\n",
    "        tweet_data_sub = collections.OrderedDict()\n",
    "        tweet_data_all = json.loads(json_obj)\n",
    "\n",
    "        # Get all of the data we're interested in\n",
    "        tweet_data_sub['id'] = tweet_data_all['id']\n",
    "        tweet_data_sub['retweet_count'] = tweet_data_all['retweet_count']\n",
    "        tweet_data_sub['favorite_count'] = tweet_data_all['favorite_count']\n",
    "\n",
    "        # Append it to the data gathering list\n",
    "        tweet_data.append(tweet_data_sub)\n",
    "\n",
    "# Create a dataframe from the data\n",
    "tweet_data_extra = pd.DataFrame(tweet_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
